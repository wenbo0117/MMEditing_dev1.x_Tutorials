{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff9d74c-10ed-40c5-9301-29145a94305a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 在自定义数据集上训练mattor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cc9482-9159-40aa-8dbb-59cc6ad195de",
   "metadata": {},
   "source": [
    "1.提供一个新的数据集\n",
    "2.修改config\n",
    "3.训练一个新的mattor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93065e47-582f-42a6-9016-4f6cd53e16c2",
   "metadata": {},
   "source": [
    "## 进入 MMEditing 主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ffb4e0d-106e-49dd-a793-91107d662267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.circleci',\n",
       " '.dele.yml',\n",
       " '.dev_scripts',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " '.owners.yml',\n",
       " '.pre-commit-config.yaml',\n",
       " '.pylintrc',\n",
       " '.readthedocs.yml',\n",
       " 'CITATION.cff',\n",
       " 'LICENSE',\n",
       " 'MANIFEST.in',\n",
       " 'README.md',\n",
       " 'README_zh-CN.md',\n",
       " 'configs',\n",
       " 'demo',\n",
       " 'docker',\n",
       " 'docs',\n",
       " 'mmedit',\n",
       " 'model-index.yml',\n",
       " 'projects',\n",
       " 'requirements.txt',\n",
       " 'requirements',\n",
       " 'setup.cfg',\n",
       " 'setup.py',\n",
       " 'tests',\n",
       " 'tools',\n",
       " 'mmedit.egg-info',\n",
       " 'outputs',\n",
       " 'data',\n",
       " 'checkpoints',\n",
       " 'work_dirs']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('mmediting')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f3689-cd81-4c68-8960-2bb139c65a89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 提供一个新的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea6c58b-46c3-4682-aac6-142ee02d72aa",
   "metadata": {},
   "source": [
    "在本教程中，我们给出了一个将数据转换成现有数据集格式的例子。\n",
    "\n",
    "首先，让我们从alphamatting.com 下载唯一可用的开源抠图数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb9543a9-c2ed-4eeb-b558-6572c8945860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 17.3M  100 17.3M    0     0  2997k      0  0:00:05  0:00:05 --:--:-- 4626k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  366k  100  366k    0     0   217k      0  0:00:01  0:00:01 --:--:--  216k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2215k  100 2215k    0     0   726k      0  0:00:03  0:00:03 --:--:--  726k\n",
      "Archive:  data/alphamatting/input_training_lowres.zip\n",
      "  inflating: data/alphamatting/merged/GT27.png  \n",
      "  inflating: data/alphamatting/merged/GT01.png  \n",
      "  inflating: data/alphamatting/merged/GT02.png  \n",
      "  inflating: data/alphamatting/merged/GT03.png  \n",
      "  inflating: data/alphamatting/merged/GT04.png  \n",
      "  inflating: data/alphamatting/merged/GT05.png  \n",
      "  inflating: data/alphamatting/merged/GT06.png  \n",
      "  inflating: data/alphamatting/merged/GT07.png  \n",
      "  inflating: data/alphamatting/merged/GT08.png  \n",
      "  inflating: data/alphamatting/merged/GT09.png  \n",
      "  inflating: data/alphamatting/merged/GT10.png  \n",
      "  inflating: data/alphamatting/merged/GT11.png  \n",
      "  inflating: data/alphamatting/merged/GT12.png  \n",
      "  inflating: data/alphamatting/merged/GT13.png  \n",
      "  inflating: data/alphamatting/merged/GT14.png  \n",
      "  inflating: data/alphamatting/merged/GT15.png  \n",
      "  inflating: data/alphamatting/merged/GT16.png  \n",
      "  inflating: data/alphamatting/merged/GT17.png  \n",
      "  inflating: data/alphamatting/merged/GT18.png  \n",
      "  inflating: data/alphamatting/merged/GT19.png  \n",
      "  inflating: data/alphamatting/merged/GT20.png  \n",
      "  inflating: data/alphamatting/merged/GT21.png  \n",
      "  inflating: data/alphamatting/merged/GT22.png  \n",
      "  inflating: data/alphamatting/merged/GT23.png  \n",
      "  inflating: data/alphamatting/merged/GT24.png  \n",
      "  inflating: data/alphamatting/merged/GT25.png  \n",
      "  inflating: data/alphamatting/merged/GT26.png  \n",
      "Archive:  data/alphamatting/trimap_training_lowres.zip\n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT01.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT02.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT03.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT04.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT05.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT06.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT07.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT08.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT09.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT10.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT11.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT12.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT13.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT14.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT15.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT16.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT17.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT18.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT19.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT20.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT21.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT22.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT23.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT24.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT25.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT26.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap2/GT27.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT01.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT02.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT03.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT04.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT05.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT06.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT07.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT08.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT09.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT10.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT11.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT12.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT13.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT14.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT15.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT16.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT17.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT18.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT19.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT20.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT21.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT22.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT23.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT24.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT25.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT26.png  \n",
      "  inflating: data/alphamatting/trimap/Trimap1/GT27.png  \n",
      "Archive:  data/alphamatting/gt_training_lowres.zip\n",
      "  inflating: data/alphamatting/alpha/GT27.png  \n",
      "  inflating: data/alphamatting/alpha/GT01.png  \n",
      "  inflating: data/alphamatting/alpha/GT02.png  \n",
      "  inflating: data/alphamatting/alpha/GT03.png  \n",
      "  inflating: data/alphamatting/alpha/GT04.png  \n",
      "  inflating: data/alphamatting/alpha/GT05.png  \n",
      "  inflating: data/alphamatting/alpha/GT06.png  \n",
      "  inflating: data/alphamatting/alpha/GT07.png  \n",
      "  inflating: data/alphamatting/alpha/GT08.png  \n",
      "  inflating: data/alphamatting/alpha/GT09.png  \n",
      "  inflating: data/alphamatting/alpha/GT10.png  \n",
      "  inflating: data/alphamatting/alpha/GT11.png  \n",
      "  inflating: data/alphamatting/alpha/GT12.png  \n",
      "  inflating: data/alphamatting/alpha/GT13.png  \n",
      "  inflating: data/alphamatting/alpha/GT14.png  \n",
      "  inflating: data/alphamatting/alpha/GT15.png  \n",
      "  inflating: data/alphamatting/alpha/GT16.png  \n",
      "  inflating: data/alphamatting/alpha/GT17.png  \n",
      "  inflating: data/alphamatting/alpha/GT18.png  \n",
      "  inflating: data/alphamatting/alpha/GT19.png  \n",
      "  inflating: data/alphamatting/alpha/GT20.png  \n",
      "  inflating: data/alphamatting/alpha/GT21.png  \n",
      "  inflating: data/alphamatting/alpha/GT22.png  \n",
      "  inflating: data/alphamatting/alpha/GT23.png  \n",
      "  inflating: data/alphamatting/alpha/GT24.png  \n",
      "  inflating: data/alphamatting/alpha/GT25.png  \n",
      "  inflating: data/alphamatting/alpha/GT26.png  \n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data/alphamatting/\n",
    "!curl http://alphamatting.com/datasets/zip/input_training_lowres.zip -o data/alphamatting/input_training_lowres.zip\n",
    "!curl http://alphamatting.com/datasets/zip/trimap_training_lowres.zip -o data/alphamatting/trimap_training_lowres.zip\n",
    "!curl http://alphamatting.com/datasets/zip/gt_training_lowres.zip -o data/alphamatting/gt_training_lowres.zip\n",
    "!unzip -o data/alphamatting/input_training_lowres.zip -d data/alphamatting/merged\n",
    "!unzip -o data/alphamatting/trimap_training_lowres.zip -d data/alphamatting/trimap\n",
    "!unzip -o data/alphamatting/gt_training_lowres.zip -d data/alphamatting/alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85594b91-0bf3-4a99-ada4-2bdb6fef4714",
   "metadata": {},
   "source": [
    "然后，我们为训练数据创建注释文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af8a8529-141d-437c-a626-5e6316533779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20个样本进行训练，7个样本进行测试\n",
    "num_file = 27\n",
    "num_training = 20  \n",
    "\n",
    "training_ann = list()\n",
    "for i in range(num_training):\n",
    "  ann = dict()\n",
    "  ann['merged_path'] = f'merged/GT{i+1:02d}.png'\n",
    "  ann['alpha_path'] = f'alpha/GT{i+1:02d}.png'\n",
    "  #由于来自alphamatting.com的数据没有合成，我们使用原始图像\n",
    "  #作为fg 和 bg\n",
    "  ann['fg_path'] = ann['merged_path']\n",
    "  ann['bg_path'] = ann['merged_path']\n",
    "  training_ann.append(ann)\n",
    "\n",
    "from mmengine import dump\n",
    "dump(training_ann, './data/alphamatting/training_list.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b6a27-722f-4b8c-9cf8-f3d7ff5378a7",
   "metadata": {},
   "source": [
    "让我们以同样的方式为测试数据创建注释文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "002aac84-39c4-4bd9-87ef-a4a1732e3430",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trimap = 1\n",
    "test_ann = list()\n",
    "for i in range(num_training, num_file):\n",
    "  for j in range(num_trimap):\n",
    "    ann = dict()\n",
    "    ann['merged_path'] = f'merged/GT{i+1:02d}.png'\n",
    "    ann['trimap_path'] = f'trimap/Trimap{j+1}/GT{i+1:02d}.png'\n",
    "    ann['alpha_path'] = f'alpha/GT{i+1:02d}.png'\n",
    "    test_ann.append(ann)\n",
    "\n",
    "dump(test_ann, './data/alphamatting/test_list.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d759803f-89ef-4537-bdf2-15515bc3b19f",
   "metadata": {},
   "source": [
    "## 修改config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed3b1c-2671-413a-899b-0cea6fb6aa5d",
   "metadata": {},
   "source": [
    "在下一步中，我们需要修改训练的config。为了加速这个过程，我们使用一个预先训练好的mattor微调一个mattor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a4a04c-b708-4921-9f5a-a0353525f96d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_type = 'AdobeComp1kDataset'\n",
      "data_root = 'data/adobe_composition-1k'\n",
      "train_dataloader = dict(\n",
      "    num_workers=8,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(type='InfiniteSampler', shuffle=True),\n",
      "    dataset=dict(\n",
      "        type='AdobeComp1kDataset',\n",
      "        data_root='data/adobe_composition-1k',\n",
      "        ann_file='training_list.json',\n",
      "        test_mode=False,\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='LoadImageFromFile', key='alpha', color_type='grayscale'),\n",
      "            dict(type='LoadImageFromFile', key='fg'),\n",
      "            dict(type='LoadImageFromFile', key='bg'),\n",
      "            dict(type='LoadImageFromFile', key='merged'),\n",
      "            dict(type='GenerateTrimapWithDistTransform', dist_thr=20),\n",
      "            dict(\n",
      "                type='CropAroundUnknown',\n",
      "                keys=['alpha', 'merged', 'fg', 'bg', 'trimap'],\n",
      "                crop_sizes=[320, 480, 640],\n",
      "                interpolations=[\n",
      "                    'bicubic', 'bicubic', 'bicubic', 'bicubic', 'nearest'\n",
      "                ]),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                keys=['trimap'],\n",
      "                scale=(320, 320),\n",
      "                keep_ratio=False,\n",
      "                interpolation='nearest'),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                keys=['alpha', 'merged', 'fg', 'bg'],\n",
      "                scale=(320, 320),\n",
      "                keep_ratio=False,\n",
      "                interpolation='bicubic'),\n",
      "            dict(type='Flip', keys=['alpha', 'merged', 'fg', 'bg', 'trimap']),\n",
      "            dict(type='PackEditInputs')\n",
      "        ]),\n",
      "    batch_size=16)\n",
      "val_dataloader = dict(\n",
      "    num_workers=4,\n",
      "    persistent_workers=False,\n",
      "    drop_last=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='AdobeComp1kDataset',\n",
      "        data_root='data/adobe_composition-1k',\n",
      "        ann_file='test_list.json',\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='LoadImageFromFile',\n",
      "                key='alpha',\n",
      "                color_type='grayscale',\n",
      "                save_original_img=True),\n",
      "            dict(\n",
      "                type='LoadImageFromFile',\n",
      "                key='trimap',\n",
      "                color_type='grayscale',\n",
      "                save_original_img=True),\n",
      "            dict(type='LoadImageFromFile', key='merged'),\n",
      "            dict(type='PackEditInputs')\n",
      "        ]),\n",
      "    batch_size=1)\n",
      "test_dataloader = dict(\n",
      "    num_workers=4,\n",
      "    persistent_workers=False,\n",
      "    drop_last=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='AdobeComp1kDataset',\n",
      "        data_root='data/adobe_composition-1k',\n",
      "        ann_file='test_list.json',\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='LoadImageFromFile',\n",
      "                key='alpha',\n",
      "                color_type='grayscale',\n",
      "                save_original_img=True),\n",
      "            dict(\n",
      "                type='LoadImageFromFile',\n",
      "                key='trimap',\n",
      "                color_type='grayscale',\n",
      "                save_original_img=True),\n",
      "            dict(type='LoadImageFromFile', key='merged'),\n",
      "            dict(type='PackEditInputs')\n",
      "        ]),\n",
      "    batch_size=1)\n",
      "val_evaluator = [\n",
      "    dict(type='SAD'),\n",
      "    dict(type='MattingMSE'),\n",
      "    dict(type='GradientError'),\n",
      "    dict(type='ConnectivityError')\n",
      "]\n",
      "test_evaluator = [\n",
      "    dict(type='SAD'),\n",
      "    dict(type='MattingMSE'),\n",
      "    dict(type='GradientError'),\n",
      "    dict(type='ConnectivityError')\n",
      "]\n",
      "default_scope = 'mmedit'\n",
      "save_dir = './work_dirs/'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=100),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(\n",
      "        type='CheckpointHook',\n",
      "        interval=2600,\n",
      "        by_epoch=False,\n",
      "        out_dir='./work_dirs/'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'))\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=4),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [dict(type='LocalVisBackend')]\n",
      "visualizer = dict(\n",
      "    type='ConcatImageVisualizer',\n",
      "    vis_backends=[dict(type='LocalVisBackend')],\n",
      "    fn_key='trimap_path',\n",
      "    img_keys=['pred_alpha', 'trimap', 'gt_merged', 'gt_alpha'],\n",
      "    bgr2rgb=True)\n",
      "custom_hooks = [dict(type='BasicVisualizationHook', interval=2000)]\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(type='LogProcessor', by_epoch=False)\n",
      "load_from = None\n",
      "resume = False\n",
      "experiment_name = 'indexnet_mobv2_1xb16-78k_comp1k'\n",
      "work_dir = './work_dirs/indexnet_mobv2_1xb16-78k_comp1k'\n",
      "model = dict(\n",
      "    type='IndexNet',\n",
      "    data_preprocessor=dict(\n",
      "        type='MattorPreprocessor',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        bgr_to_rgb=True,\n",
      "        proc_inputs='normalize',\n",
      "        proc_trimap='rescale_to_zero_one',\n",
      "        proc_gt='rescale_to_zero_one'),\n",
      "    backbone=dict(\n",
      "        type='SimpleEncoderDecoder',\n",
      "        encoder=dict(\n",
      "            type='IndexNetEncoder',\n",
      "            in_channels=4,\n",
      "            freeze_bn=True,\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained',\n",
      "                checkpoint='open-mmlab://mmedit/mobilenet_v2')),\n",
      "        decoder=dict(type='IndexNetDecoder')),\n",
      "    loss_alpha=dict(type='CharbonnierLoss', loss_weight=0.5, sample_wise=True),\n",
      "    loss_comp=dict(\n",
      "        type='CharbonnierCompLoss', loss_weight=1.5, sample_wise=True),\n",
      "    test_cfg=dict(\n",
      "        resize_method='interp', resize_mode='bicubic', size_divisor=32))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', key='alpha', color_type='grayscale'),\n",
      "    dict(type='LoadImageFromFile', key='fg'),\n",
      "    dict(type='LoadImageFromFile', key='bg'),\n",
      "    dict(type='LoadImageFromFile', key='merged'),\n",
      "    dict(type='GenerateTrimapWithDistTransform', dist_thr=20),\n",
      "    dict(\n",
      "        type='CropAroundUnknown',\n",
      "        keys=['alpha', 'merged', 'fg', 'bg', 'trimap'],\n",
      "        crop_sizes=[320, 480, 640],\n",
      "        interpolations=['bicubic', 'bicubic', 'bicubic', 'bicubic',\n",
      "                        'nearest']),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        keys=['trimap'],\n",
      "        scale=(320, 320),\n",
      "        keep_ratio=False,\n",
      "        interpolation='nearest'),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        keys=['alpha', 'merged', 'fg', 'bg'],\n",
      "        scale=(320, 320),\n",
      "        keep_ratio=False,\n",
      "        interpolation='bicubic'),\n",
      "    dict(type='Flip', keys=['alpha', 'merged', 'fg', 'bg', 'trimap']),\n",
      "    dict(type='PackEditInputs')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='LoadImageFromFile',\n",
      "        key='alpha',\n",
      "        color_type='grayscale',\n",
      "        save_original_img=True),\n",
      "    dict(\n",
      "        type='LoadImageFromFile',\n",
      "        key='trimap',\n",
      "        color_type='grayscale',\n",
      "        save_original_img=True),\n",
      "    dict(type='LoadImageFromFile', key='merged'),\n",
      "    dict(type='PackEditInputs')\n",
      "]\n",
      "train_cfg = dict(type='IterBasedTrainLoop', max_iters=78000, val_interval=2600)\n",
      "val_cfg = dict(type='ValLoop')\n",
      "test_cfg = dict(type='TestLoop')\n",
      "optim_wrapper = dict(\n",
      "    type='OptimWrapper',\n",
      "    optimizer=dict(type='Adam', lr=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict({'encoder.layers': dict(lr_mult=0.01)})))\n",
      "param_scheduler = dict(\n",
      "    type='MultiStepLR', milestones=[52000, 67600], gamma=0.1, by_epoch=False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('configs/indexnet/indexnet_mobv2_1xb16-78k_comp1k.py')\n",
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf46ec58-894b-4a95-bdfb-ac5b793ae6ed",
   "metadata": {},
   "source": [
    "给定一个在Adobe Composition-1k数据集上训练IndexNet模型的config，我们需要修改一些值来使用它在我们刚刚创建的数据集上训练IndexNet。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55686fcc-82b9-4c64-b5a7-ebcf6b995760",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_type = 'AdobeComp1kDataset'\n",
      "data_root = 'data/adobe_composition-1k'\n",
      "train_dataloader = dict(\n",
      "    num_workers=8,\n",
      "    persistent_workers=False,\n",
      "    sampler=4,\n",
      "    dataset=dict(\n",
      "        type='AdobeComp1kDataset',\n",
      "        data_root='data/adobe_composition-1k',\n",
      "        ann_file='training_list.json',\n",
      "        test_mode=False,\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='LoadImageFromFile', key='alpha', color_type='grayscale'),\n",
      "            dict(type='LoadImageFromFile', key='fg'),\n",
      "            dict(type='LoadImageFromFile', key='bg'),\n",
      "            dict(type='LoadImageFromFile', key='merged'),\n",
      "            dict(type='GenerateTrimapWithDistTransform', dist_thr=20),\n",
      "            dict(\n",
      "                type='CropAroundUnknown',\n",
      "                keys=['alpha', 'merged', 'fg', 'bg', 'trimap'],\n",
      "                crop_sizes=[320, 480, 640],\n",
      "                interpolations=[\n",
      "                    'bicubic', 'bicubic', 'bicubic', 'bicubic', 'nearest'\n",
      "                ]),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                keys=['trimap'],\n",
      "                scale=(320, 320),\n",
      "                keep_ratio=False,\n",
      "                interpolation='nearest'),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                keys=['alpha', 'merged', 'fg', 'bg'],\n",
      "                scale=(320, 320),\n",
      "                keep_ratio=False,\n",
      "                interpolation='bicubic'),\n",
      "            dict(type='Flip', keys=['alpha', 'merged', 'fg', 'bg', 'trimap']),\n",
      "            dict(type='PackEditInputs')\n",
      "        ]),\n",
      "    batch_size=16,\n",
      "    workers_per_gpu=1)\n",
      "val_dataloader = dict(\n",
      "    num_workers=4,\n",
      "    persistent_workers=False,\n",
      "    drop_last=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='AdobeComp1kDataset',\n",
      "        data_root='data/adobe_composition-1k',\n",
      "        ann_file='test_list.json',\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='LoadImageFromFile',\n",
      "                key='alpha',\n",
      "                color_type='grayscale',\n",
      "                save_original_img=True),\n",
      "            dict(\n",
      "                type='LoadImageFromFile',\n",
      "                key='trimap',\n",
      "                color_type='grayscale',\n",
      "                save_original_img=True),\n",
      "            dict(type='LoadImageFromFile', key='merged'),\n",
      "            dict(type='PackEditInputs')\n",
      "        ]),\n",
      "    batch_size=1)\n",
      "test_dataloader = dict(\n",
      "    num_workers=4,\n",
      "    persistent_workers=False,\n",
      "    drop_last=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='AdobeComp1kDataset',\n",
      "        data_root='data/adobe_composition-1k',\n",
      "        ann_file='test_list.json',\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='LoadImageFromFile',\n",
      "                key='alpha',\n",
      "                color_type='grayscale',\n",
      "                save_original_img=True),\n",
      "            dict(\n",
      "                type='LoadImageFromFile',\n",
      "                key='trimap',\n",
      "                color_type='grayscale',\n",
      "                save_original_img=True),\n",
      "            dict(type='LoadImageFromFile', key='merged'),\n",
      "            dict(type='PackEditInputs')\n",
      "        ]),\n",
      "    batch_size=1)\n",
      "val_evaluator = [\n",
      "    dict(type='SAD'),\n",
      "    dict(type='MattingMSE'),\n",
      "    dict(type='GradientError'),\n",
      "    dict(type='ConnectivityError')\n",
      "]\n",
      "test_evaluator = [\n",
      "    dict(type='SAD'),\n",
      "    dict(type='MattingMSE'),\n",
      "    dict(type='GradientError'),\n",
      "    dict(type='ConnectivityError')\n",
      "]\n",
      "default_scope = 'mmedit'\n",
      "save_dir = './work_dirs/'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=100),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(\n",
      "        type='CheckpointHook',\n",
      "        interval=2600,\n",
      "        by_epoch=False,\n",
      "        out_dir='./work_dirs/'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'))\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=4),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [dict(type='LocalVisBackend')]\n",
      "visualizer = dict(\n",
      "    type='ConcatImageVisualizer',\n",
      "    vis_backends=[dict(type='LocalVisBackend')],\n",
      "    fn_key='trimap_path',\n",
      "    img_keys=['pred_alpha', 'trimap', 'gt_merged', 'gt_alpha'],\n",
      "    bgr2rgb=True)\n",
      "custom_hooks = [dict(type='BasicVisualizationHook', interval=2000)]\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(type='LogProcessor', by_epoch=False)\n",
      "load_from = 'indexnet_mobv2_1x16_78k_comp1k_SAD-45.6_20200618_173817-26dd258d.pth'\n",
      "resume = False\n",
      "experiment_name = 'indexnet_mobv2_1xb16-78k_comp1k'\n",
      "work_dir = './tutorial_exps/indexnet'\n",
      "model = dict(\n",
      "    type='IndexNet',\n",
      "    data_preprocessor=dict(\n",
      "        type='MattorPreprocessor',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        bgr_to_rgb=True,\n",
      "        proc_inputs='normalize',\n",
      "        proc_trimap='rescale_to_zero_one',\n",
      "        proc_gt='rescale_to_zero_one'),\n",
      "    backbone=dict(\n",
      "        type='SimpleEncoderDecoder',\n",
      "        encoder=dict(\n",
      "            type='IndexNetEncoder',\n",
      "            in_channels=4,\n",
      "            freeze_bn=True,\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained',\n",
      "                checkpoint='open-mmlab://mmedit/mobilenet_v2')),\n",
      "        decoder=dict(type='IndexNetDecoder')),\n",
      "    loss_alpha=dict(type='CharbonnierLoss', loss_weight=0.5, sample_wise=True),\n",
      "    loss_comp=dict(\n",
      "        type='CharbonnierCompLoss', loss_weight=1.5, sample_wise=True),\n",
      "    test_cfg=dict(\n",
      "        resize_method='interp', resize_mode='bicubic', size_divisor=32),\n",
      "    pretrained=None)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', key='alpha', color_type='grayscale'),\n",
      "    dict(type='LoadImageFromFile', key='fg'),\n",
      "    dict(type='LoadImageFromFile', key='bg'),\n",
      "    dict(type='LoadImageFromFile', key='merged'),\n",
      "    dict(type='GenerateTrimapWithDistTransform', dist_thr=20),\n",
      "    dict(\n",
      "        type='CropAroundUnknown',\n",
      "        keys=['alpha', 'merged', 'fg', 'bg', 'trimap'],\n",
      "        crop_sizes=[320, 480, 640],\n",
      "        interpolations=['bicubic', 'bicubic', 'bicubic', 'bicubic',\n",
      "                        'nearest']),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        keys=['trimap'],\n",
      "        scale=(320, 320),\n",
      "        keep_ratio=False,\n",
      "        interpolation='nearest'),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        keys=['alpha', 'merged', 'fg', 'bg'],\n",
      "        scale=(320, 320),\n",
      "        keep_ratio=False,\n",
      "        interpolation='bicubic'),\n",
      "    dict(type='Flip', keys=['alpha', 'merged', 'fg', 'bg', 'trimap']),\n",
      "    dict(type='PackEditInputs')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='LoadImageFromFile',\n",
      "        key='alpha',\n",
      "        color_type='grayscale',\n",
      "        save_original_img=True),\n",
      "    dict(\n",
      "        type='LoadImageFromFile',\n",
      "        key='trimap',\n",
      "        color_type='grayscale',\n",
      "        save_original_img=True),\n",
      "    dict(type='LoadImageFromFile', key='merged'),\n",
      "    dict(type='PackEditInputs')\n",
      "]\n",
      "train_cfg = dict(\n",
      "    type='AdobeComp1kDataset',\n",
      "    max_iters=78000,\n",
      "    val_interval=20,\n",
      "    ann_file='./data/alphamatting/training_list.json',\n",
      "    data_prefix='./data/alphamatting/')\n",
      "val_cfg = dict(\n",
      "    type='AdobeComp1kDataset',\n",
      "    ann_file='./data/alphamatting/test_list.json',\n",
      "    data_prefix='./data/alphamatting/')\n",
      "test_cfg = dict(\n",
      "    type='AdobeComp1kDataset',\n",
      "    ann_file='./data/alphamatting/test_list.json',\n",
      "    data_prefix='./data/alphamatting/')\n",
      "optim_wrapper = dict(\n",
      "    type='OptimWrapper',\n",
      "    optimizer=dict(type='Adam', lr=0.0025),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict({'encoder.layers': dict(lr_mult=0.01)})))\n",
      "param_scheduler = dict(\n",
      "    type='MultiStepLR', milestones=[52000, 67600], gamma=0.1, by_epoch=False)\n",
      "total_iters = 50\n",
      "lr_config = None\n",
      "seed = 0\n",
      "gpus = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('configs/indexnet/indexnet_mobv2_1xb16-78k_comp1k.py')\n",
    "\n",
    "from mmengine.runner import set_random_seed\n",
    "\n",
    "# 修改数据集类型和路径\n",
    "cfg.train_cfg.type = 'AdobeComp1kDataset'\n",
    "cfg.train_cfg.ann_file = './data/alphamatting/training_list.json'\n",
    "cfg.train_cfg.data_prefix = './data/alphamatting/'\n",
    "\n",
    "cfg.val_cfg.type = 'AdobeComp1kDataset'\n",
    "cfg.val_cfg.ann_file = './data/alphamatting/test_list.json'\n",
    "cfg.val_cfg.data_prefix = './data/alphamatting/'\n",
    "\n",
    "cfg.test_cfg.type = 'AdobeComp1kDataset'\n",
    "cfg.test_cfg.ann_file = './data/alphamatting/test_list.json'\n",
    "cfg.test_cfg.data_prefix = './data/alphamatting/'\n",
    "\n",
    "# 我们可以使用预先训练的IndexNet模型\n",
    "cfg.model.pretrained = None\n",
    "cfg.load_from = 'indexnet_mobv2_1x16_78k_comp1k_SAD-45.6_20200618_173817-26dd258d.pth'\n",
    "\n",
    "# 设置工作目录来保存文件和日志\n",
    "cfg.work_dir = './tutorial_exps/indexnet'\n",
    "\n",
    "# 使用小batch size训练\n",
    "cfg.train_dataloader.sampler = 4\n",
    "cfg.train_dataloader.workers_per_gpu = 1\n",
    "\n",
    "#原始学习率(LR)设置batch size为16，使用1个GPU。\n",
    "#我们将LR降低了4倍，因为我们减少了batch size大小。\n",
    "cfg.optim_wrapper.optimizer.lr = cfg.optim_wrapper.optimizer.lr / 4\n",
    "cfg.total_iters = 50\n",
    "cfg.lr_config = None\n",
    "\n",
    "# 每20次迭代评估一次\n",
    "cfg.train_cfg.val_interval = 20\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpus = 1\n",
    "\n",
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f56fe97-3f36-4d6b-85ca-c4531cc7fe8a",
   "metadata": {},
   "source": [
    "## 训练一个新的mattor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e248b34-b990-4c51-9b2e-43467267d56d",
   "metadata": {},
   "source": [
    "最后，让我们初始化数据集和mattor，然后训练一个新的mattor！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1da51d9-02ce-45ed-a820-a6066cea7b2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not ConfigDict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2091/409784243.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 构建数据集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mAdobeComp1kDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 构建mattor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/environment/miniconda3/lib/python3.7/site-packages/mmengine/dataset/base_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ann_file, metainfo, data_root, data_prefix, filter_cfg, indices, serialize_data, pipeline, test_mode, lazy_init, max_refetch)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# Join paths.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_join_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;31m# Build pipeline.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/environment/miniconda3/lib/python3.7/site-packages/mmengine/dataset/base_dataset.py\u001b[0m in \u001b[0;36m_join_prefix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Automatically join annotation file path with `self.root` if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;31m# `self.ann_file` is not an absolute path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mann_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mann_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mann_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mann_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;31m# Automatically join data directory with `self.root` if path value in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/environment/miniconda3/lib/python3.7/site-packages/mmengine/utils/path.py\u001b[0m in \u001b[0;36mis_abs\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0man\u001b[0m \u001b[0mabsolute\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'https://'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's3://'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/environment/miniconda3/lib/python3.7/posixpath.py\u001b[0m in \u001b[0;36misabs\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0misabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m\"\"\"Test whether a path is absolute\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not ConfigDict"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmedit.datasets import AdobeComp1kDataset\n",
    "from mmedit.models import BaseEditModel\n",
    "from mmedit.apis import init_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# 构建数据集\n",
    "datasets = [AdobeComp1kDataset(cfg.train_cfg)]\n",
    "\n",
    "# 构建mattor\n",
    "model = BaseEditModel(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# 创建工作目录\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "# 训练模型\n",
    "init_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86da79-25cd-4e96-b2a0-cb30f674450a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
